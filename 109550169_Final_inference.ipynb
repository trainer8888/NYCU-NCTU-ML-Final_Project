{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os\nimport numpy as np\nimport pandas as pd\n\n# Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Scoring and Cross-Validation\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\n# Imputation and Preprocessing\nfrom sklearn.preprocessing import RobustScaler\nfrom category_encoders import WOEEncoder\nfrom sklearn.impute import KNNImputer\n\n# Pipeline Constructors\nfrom sklearn.pipeline import make_pipeline\n\n# Linear Models\nfrom sklearn.linear_model import LogisticRegression, HuberRegressor\n\n# save and load the model\nfrom joblib import dump, load","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:48:19.966221Z","iopub.execute_input":"2023-01-09T23:48:19.966722Z","iopub.status.idle":"2023-01-09T23:48:19.974712Z","shell.execute_reply.started":"2023-01-09T23:48:19.966688Z","shell.execute_reply":"2023-01-09T23:48:19.973689Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"def prepreprocessing(df_train, df_test):\n    data = pd.concat([df_train, df_test])\n    \n    df_train = data.iloc[:df_train.shape[0],:]\n    df_test = data.iloc[df_train.shape[0]:,:]\n    \n    # WOE Encoding\n    encoder = WOEEncoder(cols = ['attribute_0'])\n    df_train = encoder.fit_transform(df_train, target)\n    df_test = encoder.transform(df_test)\n    \n    # Log transform\n    df_train['loading'] = np.log1p(df_train['loading'])\n    df_test['loading'] = np.log1p(df_test['loading'])\n    \n    df_train = df_train.drop(labels=[\"attribute_1\"], axis=\"columns\")\n    df_test = df_test.drop(labels=[\"attribute_1\"], axis=\"columns\")\n    \n    feature_names = df_train.columns.values\n    for feature in feature_names:\n        if df_train[feature].isnull().values.any():\n            df_train[feature] = df_train[feature].fillna(df_train[feature].median())\n        if df_test[feature].isnull().values.any():\n            df_test[feature] = df_test[feature].fillna(df_test[feature].median())\n    \n    return df_train, df_test, feature_names","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:48:23.646132Z","iopub.execute_input":"2023-01-09T23:48:23.646615Z","iopub.status.idle":"2023-01-09T23:48:23.658589Z","shell.execute_reply.started":"2023-01-09T23:48:23.646577Z","shell.execute_reply":"2023-01-09T23:48:23.656965Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Load data and model\nsubmission = pd.read_csv('/kaggle/input/final-project-dataset/sample_submission.csv')\ntrain = pd.read_csv('/kaggle/input/final-project-dataset/train.csv', index_col = 'id') \ntest = pd.read_csv('/kaggle/input/final-project-dataset/test.csv', index_col = 'id')\nmodel = load('/kaggle/input/final-project-dataset/model.joblib')\n\n# Save target column\ntarget = train['failure'].copy()\n\ntrain, test, columns = prepreprocessing(train, test)","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:49:18.843179Z","iopub.execute_input":"2023-01-09T23:49:18.843809Z","iopub.status.idle":"2023-01-09T23:49:19.296920Z","shell.execute_reply.started":"2023-01-09T23:49:18.843757Z","shell.execute_reply":"2023-01-09T23:49:19.295785Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"SPLITS = []\nindices = list(train.groupby(\"product_code\").indices.values())\nfor i in range(len(indices)):\n    for j in range(i+1, len(indices)):\n        SPLITS.append([np.concatenate([ix for k, ix in enumerate(indices) if k not in [i, j]]),\n                       np.concatenate([ix for k, ix in enumerate(indices) if k in [i, j]])])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:49:23.295112Z","iopub.execute_input":"2023-01-09T23:49:23.295611Z","iopub.status.idle":"2023-01-09T23:49:23.308967Z","shell.execute_reply.started":"2023-01-09T23:49:23.295570Z","shell.execute_reply":"2023-01-09T23:49:23.307625Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Stores predictions and scores\ntest_preds = np.zeros((test.shape[0],))\nif \"product_code\" in test.columns:\n    test = test.drop(labels=[\"product_code\"], axis=\"columns\")\ncolumns = test.columns.values\n# Training and Validation Splits\nfor fold, (train_idx, valid_idx) in enumerate(SPLITS):\n    # Get predictions\n    if test[\"failure\"].isnull().values.any():\n        test[\"failure\"] = test[\"failure\"].fillna(0)\n    test_preds += model.predict_proba(test[columns])[:, 1] / len(SPLITS)\npreds = test_preds\nsubmission['failure'] = preds\nsubmission.to_csv('submission.csv', index=False)\nprint('Sucessfully Saved')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:49:29.034980Z","iopub.execute_input":"2023-01-09T23:49:29.035629Z","iopub.status.idle":"2023-01-09T23:49:29.332953Z","shell.execute_reply.started":"2023-01-09T23:49:29.035573Z","shell.execute_reply":"2023-01-09T23:49:29.331291Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Sucessfully Saved\n","output_type":"stream"}]}]}