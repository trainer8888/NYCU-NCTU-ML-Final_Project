{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports\nimport os\nimport numpy as np\nimport pandas as pd\n\n# Hide warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Scoring and Cross-Validation\nfrom sklearn.metrics import roc_auc_score, accuracy_score\n\n# Imputation and Preprocessing\nfrom sklearn.preprocessing import RobustScaler\nfrom category_encoders import WOEEncoder\nfrom sklearn.impute import KNNImputer\n\n# Pipeline Constructors\nfrom sklearn.pipeline import make_pipeline\n\n# Linear Models\nfrom sklearn.linear_model import LogisticRegression, HuberRegressor\n\n# save and load the model\nfrom joblib import dump, load","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:37:33.339987Z","iopub.execute_input":"2023-01-09T23:37:33.340760Z","iopub.status.idle":"2023-01-09T23:37:33.350430Z","shell.execute_reply.started":"2023-01-09T23:37:33.340709Z","shell.execute_reply":"2023-01-09T23:37:33.348523Z"},"trusted":true},"execution_count":256,"outputs":[]},{"cell_type":"code","source":"def prepreprocessing(df_train, df_test):\n    data = pd.concat([df_train, df_test])\n    \n    df_train = data.iloc[:df_train.shape[0],:]\n    df_test = data.iloc[df_train.shape[0]:,:]\n    \n    # WOE Encoding\n    encoder = WOEEncoder(cols = ['attribute_0'])\n    df_train = encoder.fit_transform(df_train, target)\n    df_test = encoder.transform(df_test)\n    \n    # Log transform\n    df_train['loading'] = np.log1p(df_train['loading'])\n    df_test['loading'] = np.log1p(df_test['loading'])\n    \n    df_train = df_train.drop(labels=[\"attribute_1\"], axis=\"columns\")\n    df_test = df_test.drop(labels=[\"attribute_1\"], axis=\"columns\")\n    \n    feature_names = df_train.columns.values\n    for feature in feature_names:\n        if df_train[feature].isnull().values.any():\n            df_train[feature] = df_train[feature].fillna(df_train[feature].median())\n        if df_test[feature].isnull().values.any():\n            df_test[feature] = df_test[feature].fillna(df_test[feature].median())\n    \n    return df_train, df_test, feature_names","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:28:49.968529Z","iopub.execute_input":"2023-01-09T23:28:49.969235Z","iopub.status.idle":"2023-01-09T23:28:49.981143Z","shell.execute_reply.started":"2023-01-09T23:28:49.969200Z","shell.execute_reply":"2023-01-09T23:28:49.979481Z"},"trusted":true},"execution_count":250,"outputs":[]},{"cell_type":"code","source":"# Load data\nsubmission = pd.read_csv('../input/tabular-playground-series-aug-2022/sample_submission.csv')\ntrain = pd.read_csv('../input/tabular-playground-series-aug-2022/train.csv', index_col = 'id') \ntest = pd.read_csv('../input/tabular-playground-series-aug-2022/test.csv', index_col = 'id')\n\n# Save target column\ntarget = train['failure'].copy()\n\ntrain, test, columns = prepreprocessing(train, test)\n\nprint(test.values[0])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:28:52.437535Z","iopub.execute_input":"2023-01-09T23:28:52.438011Z","iopub.status.idle":"2023-01-09T23:28:52.995226Z","shell.execute_reply.started":"2023-01-09T23:28:52.437976Z","shell.execute_reply":"2023-01-09T23:28:52.993915Z"},"trusted":true},"execution_count":251,"outputs":[{"name":"stdout","text":"['F' 4.79223049712922 -0.07418665684080988 6 4 6 9 6 19.305 10.178 17.534\n 18.168 11.598 18.654 10.802 15.909 18.07 13.772 13.659 16.825 13.742\n 17.71 634.612 nan]\n","output_type":"stream"}]},{"cell_type":"code","source":"SPLITS = []\nindices = list(train.groupby(\"product_code\").indices.values())\nfor i in range(len(indices)):\n    for j in range(i+1, len(indices)):\n        SPLITS.append([np.concatenate([ix for k, ix in enumerate(indices) if k not in [i, j]]),\n                       np.concatenate([ix for k, ix in enumerate(indices) if k in [i, j]])])","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:28:54.708311Z","iopub.execute_input":"2023-01-09T23:28:54.708866Z","iopub.status.idle":"2023-01-09T23:28:54.724188Z","shell.execute_reply.started":"2023-01-09T23:28:54.708795Z","shell.execute_reply":"2023-01-09T23:28:54.722993Z"},"trusted":true},"execution_count":252,"outputs":[]},{"cell_type":"code","source":"if os.path.exists(\"/kaggle/working/submission.csv\"):\n    os.remove(\"/kaggle/working/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:29:02.167857Z","iopub.execute_input":"2023-01-09T23:29:02.169008Z","iopub.status.idle":"2023-01-09T23:29:02.176075Z","shell.execute_reply.started":"2023-01-09T23:29:02.168947Z","shell.execute_reply":"2023-01-09T23:29:02.174298Z"},"trusted":true},"execution_count":254,"outputs":[]},{"cell_type":"code","source":"# Stores predictions and scores\ntest_preds = np.zeros((test.shape[0],))\nscores = np.zeros(len(SPLITS))\nif \"product_code\" in train.columns:\n    train = train.drop(labels=[\"product_code\"], axis=\"columns\")\nif \"product_code\" in test.columns:\n    test = test.drop(labels=[\"product_code\"], axis=\"columns\")\ncolumns = train.columns.values\n# Define model\nmodel = make_pipeline(RobustScaler(), LogisticRegression())\n# Training and Validation Splits\nfor fold, (train_idx, valid_idx) in enumerate(SPLITS):\n    # Training and Validation Sets\n    X_train = train[columns].iloc[train_idx]\n    X_valid = train[columns].iloc[valid_idx]\n    y_train = target.iloc[train_idx]\n    y_valid = target.iloc[valid_idx]\n\n    # train model\n    model.fit(X_train, y_train)\n\n    # Get predictions\n    valid_preds = model.predict_proba(X_valid)[:,1]\n    if test[\"failure\"].isnull().values.any():\n        test[\"failure\"] = test[\"failure\"].fillna(0)\n    test_preds += model.predict_proba(test[columns])[:, 1] / len(SPLITS)\n    scores[fold] = roc_auc_score(y_valid, valid_preds)\n#print(f'Average accuracy: {round(np.mean(scores), 6)}')\ndump(model, 'model.joblib')\n\npreds = test_preds\nsubmission['failure'] = preds\nsubmission.to_csv('submission.csv', index=False)\nprint('Sucessfully Saved')","metadata":{"execution":{"iopub.status.busy":"2023-01-09T23:38:17.166771Z","iopub.execute_input":"2023-01-09T23:38:17.167251Z","iopub.status.idle":"2023-01-09T23:38:19.550611Z","shell.execute_reply.started":"2023-01-09T23:38:17.167214Z","shell.execute_reply":"2023-01-09T23:38:19.549585Z"},"trusted":true},"execution_count":257,"outputs":[{"name":"stdout","text":"Sucessfully Saved\n","output_type":"stream"}]}]}